# Garrett-learns-AI
A resource page for learning about basic Machine Learning, Artificial Intelligence, and Data Science (which are all different terms describing basically the same thing). 

## 60,000 ft Overview

[This video](https://www.youtube.com/watch?v=PeMlggyqz0Y) has a great 100 second summary of Machine Learning, or "ML" for short. 

ML describes a situation in which any computer is given instructions for how to 1) perform a task and 2) **assess its performance** at said task. If you tell a computer to predict the price of eggs tomorrow, it is pretty easy to imagine how to score its accuracy or "error" for that task: compare its predicted price with what the real price ends up being the next day. You, as the programmer, would be responsible for giving the computer training data, directing the computer to use a certain type of algorithm, and providing the computer with a yardstick with which to measure its performance. The actual work of doing the fancy math and computations happens automatically; you're the driver, not the mechanic. 

## Most Important Topics

In my opinion, there are five topics that are vital to understand for you to be conversant in ML and AI. None of these require technical understanding of algorithms or programming; they are just important features of ML that the general public tends not to understand but which are where most of the exciting decision-making happens for people who are dealing with data models.

### 1. What is "Artificial Intelligence"

When most normal people talk about "Artificial Intelligence" and "AI", they tend to think of a computer that can talk, can think, and can do things. OpenAI's program ChatGPT is a chatbot that can produce text in a conversational format, and seems to basically be "an AI" that can think, understand, and reason. This understanding bears cticial investigation.

The theory of artificial intelligence weds theoretical computer science with philosophy of mind. Philosophers have theorized what it means to think, know, understand, and exist long before computers were around. You, having studied philosophy, know of this history better than most people. At some point, you can try perusing a few sections of the Wikipedia page [Philosophy of Artificial Intellligence](https://en.wikipedia.org/wiki/Philosophy_of_artificial_intelligence). In particular, the introduction and first section of the [Chinese Room](https://en.wikipedia.org/wiki/Chinese_room) page are pretty instructive for introducing some critical questions about what exactly ChatGPT *is*, basically arguing that a hyperintelligent chatbot still lacks "intelligence" in the sense humans have intelligence.

The term AI refers to a broad range of computer algorithms and software that can use information and learning to improve performance at a given task. That is a very broad definition! Suppose I have data on the age of every member of the first year medical school class, and I want to understand what the "typical" student age is. I might take the average of all of the ages, and come to the result of 25. I might take the "median" age, aligning everyone in order and selecting the age of the middle person, which might be 24. "Average" and "median" are both mathematical algorithms that an elementary school student can do by hand. Does this count as AI? Every social media company uses algorithms to decide which friends to suggest, which videos to show, and which tweets and prioritize in your feed. All of this is done through software that uses ML/AI/Statistics/Data Science of some kind. Facebook's algorithm is AI, and Google trying to decide which ad to feed you at a specific time and website is AI. 

When most people hear the term "AI", they are thinking of "AGI", or Artificial General Intelligence. AGI is a theoretical state of some AI program or software that can learn, reason, and perform an immensely wide variety of tasks as intelligently as humans (or, perhaps, moreso than humans). You might think ChatGPT is an AGI, a type of software that can basically do anything a person can do with any information and given task. The actual creators of ChatGPT disagree; they think they might one day achieve AGI, but know that their chatbot software is a ways off and is extremely sensitive to its input data, training procedures, and software interface, and can't necessarily learn new things like you and I can. Experts disagree on if we will ever achieve AGI, and if so, when that might occur and what repurcussions it would have for humanity. 

In my opinion, it is almost always helpful to avoid simply saying "AI" since it can mean so many different things to so many different people. I try to stick to saying "software" or "program" since AI is just a way to tell computers to accomplish a task. Many people think of AI as chatbots, but that is not at all true. However, with all the hype of ChatGPT in the last few years, academics and companies that have been utilizing ML models for years have started branding their work as "powered by AI" which gives a mystical, futuristic connotation to what is very old, simple computer software. Most of the news about "scientists using AI to do XYZ" means someone used basic statistics to do the work they've been doing for years but that they want more media coverage. It's important to treat AI as software, not intelligence, at least for now. 

### 2. The Bias-Variance tradeoff

### 3. Types of tasks

### 4. Supervised vs. Unsupervised Learning

### 5. Error, Accuracy, and Risk

## AI in Medicine

Links: 
- [New England Journal of Medicine: AI in Medicine](https://www.nejm.org/ai-in-medicine)
- [Journal of Family Medicine and Primary Care: Overview of artificial intelligence in medicine](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6691444/)
  - Conspicuous lack of discussion regarding risk and bias!
- [Harvard Medical School: How Artificial Intelligence is Disrupting Medicine and What it Means for Physicians](https://postgraduateeducation.hms.harvard.edu/trends-medicine/how-artificial-intelligence-disrupting-medicine-what-means-physicians)

